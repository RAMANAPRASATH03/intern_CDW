{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "prices=pd.read_csv('/fb-stock-prices.csv')\n",
    "prices.head()\n",
    "\n",
    "prices.dtypes\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(prices['Price'])\n",
    "plt.show()\n",
    "\n",
    "prices.count()\n",
    "\n",
    "# DATA PREPROCESSING\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,minmax_scale\n",
    "scalar = StandardScaler()\n",
    "# Changed 'prices' to 'Price' to match the actual column name in the DataFrame\n",
    "scaled_prices = scalar.fit_transform(prices[[\"Price\"]].values)\n",
    "\n",
    "print(scaled_prices)\n",
    "\n",
    "total_size=len(scaled_prices)\n",
    "test_size=50\n",
    "train_size=total_size-test_size\n",
    "\n",
    "print(total_size)\n",
    "print(test_size)\n",
    "print(train_size)\n",
    "\n",
    "training_prices=scaled_prices[:train_size]\n",
    "test_prices = scaled_prices[train_size:]\n",
    "\n",
    "print(training_prices.shape)\n",
    "\n",
    "def create_rnn_dataset(data, look_back=1):\n",
    "    data_x=[]\n",
    "    data_y=[]\n",
    "    for i in range(len(data)-look_back-1):\n",
    "        b=data[i:(i+look_back),0]\n",
    "        data_x.append(b)\n",
    "        data_y.append(data[i+look_back,0])\n",
    "    return numpy.array(data_x),numpy.array(data_y)\n",
    "\n",
    "lookback=25\n",
    "train_req_x,train_req_y=create_rnn_dataset(training_prices,lookback)\n",
    "train_req_x.shape\n",
    "\n",
    "train_req_y.shape\n",
    "\n",
    "train_req_x=numpy.reshape(train_req_x,(train_req_x.shape[0],1,train_req_x.shape[1]))\n",
    "\n",
    "print(train_req_x.shape)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "import tensorflow as tf\n",
    "\n",
    "price_model = Sequential()\n",
    "price_model.add(SimpleRNN(32,input_shape=(1,lookback)))\n",
    "price_model.add(Dense(1))\n",
    "price_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "\n",
    "price_model.fit(train_req_x,train_req_y,epochs=5,batch_size=5,verbose=1)\n",
    "\n",
    "test_req_x,test_req_y=create_rnn_dataset(test_prices,lookback)\n",
    "test_req_x = numpy.reshape(test_req_x,(test_req_x.shape[0],1,test_req_x.shape[1]))\n",
    "\n",
    "predictions\n",
    "prev_prices = numpy.array([324,356,456,321,324,\n",
    "                        345,330,331,335,326,\n",
    "                        345,330,333,354,356,\n",
    "                        349,330,331,335,326,\n",
    "                        356,331,335,349,333])\n",
    "scaled_prices = scaler.transform(prev_prices.reshape(-1,1))\n",
    "model_input = numpy.reshape(scaled_prices,(scaled_prices.shape[1],1,scaled_prices.shape[0]))\n",
    "pred = price_model.predict(model_input)\n",
    "stock_pred = scaler.inverse_transform(pred)\n",
    "print(stock_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3 LSTM exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Load dataset\n",
    "file_path = '/mnt/data/Spam-Classification.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['CLASS'] = label_encoder.fit_transform(data['CLASS'])  # 0 for ham, 1 for spam\n",
    "\n",
    "# Tokenize SMS content\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['SMS'])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert SMS to sequences\n",
    "sequences = tokenizer.texts_to_sequences(data['SMS'])\n",
    "\n",
    "# Pad sequences\n",
    "max_length = 100  # Maximum length of SMS messages\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Prepare train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['CLASS'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LSTM model\n",
    "vocab_size = len(word_index) + 1  # Total number of unique words\n",
    "embedding_dim = 64\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Display prediction results\n",
    "print(\"Sample Predictions:\")\n",
    "for i in range(10):  # Display 10 sample predictions\n",
    "    print(f\"Message: {data['SMS'].iloc[i]}\\nActual: {y_test.iloc[i]}\\nPredicted: {predicted_classes[i][0]}\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
